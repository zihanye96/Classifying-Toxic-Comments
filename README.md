# Classification of Toxic Wikipedia Comments
The goal of this project is to construct a model to accurately classify whether or not a comment is toxic. The dataset used for training and testing consists of Wikipedia comments which have been labeled by human raters for toxicity. Using the dataset, we created 11 intuitive features from the comment text and built various classification models (Naive Bayes, Pruned Classification Tree, Random Forest, Logistic Regression, Neural Network, and SVM). The final model, which was selected using sensitivity and balanced accuracy as the criteria, was able to correctly classify toxic comments over 93\% of the time. 

The [report](report.md) discusses the project in more detail. This project was done in collaboration with Calvin Ludwig at Williams College. 


